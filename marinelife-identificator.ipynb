{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4323384,"sourceType":"datasetVersion","datasetId":2546230}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **DEPENDANCIES AND LIBRARIES**","metadata":{}},{"cell_type":"code","source":"import os\nimport PIL\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pathlib, os, random\nfrom keras.preprocessing import image\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n\n\n\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.layers import Conv2D,Add,MaxPooling2D, Dense, BatchNormalization,Input,Flatten, Dropout,GlobalMaxPooling2D,Lambda\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam,RMSprop\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:21:28.431720Z","iopub.execute_input":"2025-09-22T07:21:28.432164Z","iopub.status.idle":"2025-09-22T07:21:42.505706Z","shell.execute_reply.started":"2025-09-22T07:21:28.432144Z","shell.execute_reply":"2025-09-22T07:21:42.504931Z"}},"outputs":[{"name":"stderr","text":"2025-09-22 07:21:31.122396: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758525691.317244      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758525691.378795      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# DATA SET","metadata":{}},{"cell_type":"code","source":"#print the directory\nos.listdir('../input/fish-dataset/FishImgDataset')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:21:42.507123Z","iopub.execute_input":"2025-09-22T07:21:42.507553Z","iopub.status.idle":"2025-09-22T07:21:42.516313Z","shell.execute_reply.started":"2025-09-22T07:21:42.507535Z","shell.execute_reply":"2025-09-22T07:21:42.515568Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['val', 'test', 'train']"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"train = '../input/fish-dataset/FishImgDataset/train' #training path\nvalidation = '../input/fish-dataset/FishImgDataset/val' #validation path\ntest = '../input/fish-dataset/FishImgDataset/test' #test path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:21:42.517059Z","iopub.execute_input":"2025-09-22T07:21:42.517316Z","iopub.status.idle":"2025-09-22T07:21:42.544633Z","shell.execute_reply.started":"2025-09-22T07:21:42.517292Z","shell.execute_reply":"2025-09-22T07:21:42.543997Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#DATA AUGMENTATION\ntrain_datagen = ImageDataGenerator(rescale = 1./255, #convert to target values between 0 and 1 for faster training\n                                   shear_range = 0.2, #for randomly applying shearing transformations \n                                   zoom_range = 0.2,  # for randomly zooming inside pictures\n                                   horizontal_flip = True)#for randomly flipping half of the images horizontally)#initialize train generator \nvalid_datagen = ImageDataGenerator(rescale = 1.0/255.) #initialize validation generator \ntest_datagen = ImageDataGenerator(rescale = 1.0/255.) #initialize validation generator ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:21:42.545333Z","iopub.execute_input":"2025-09-22T07:21:42.545573Z","iopub.status.idle":"2025-09-22T07:21:42.559128Z","shell.execute_reply.started":"2025-09-22T07:21:42.545551Z","shell.execute_reply":"2025-09-22T07:21:42.558398Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(train, target_size=(224,224),batch_size=32,class_mode='categorical')\nvalidation_generator = valid_datagen.flow_from_directory(validation, target_size=(224,224),batch_size=32,class_mode='categorical')\ntest_generator = test_datagen.flow_from_directory(test, target_size=(224,224),batch_size=32,class_mode='categorical',shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:21:42.560670Z","iopub.execute_input":"2025-09-22T07:21:42.560859Z","iopub.status.idle":"2025-09-22T07:21:46.208416Z","shell.execute_reply.started":"2025-09-22T07:21:42.560844Z","shell.execute_reply":"2025-09-22T07:21:46.207725Z"}},"outputs":[{"name":"stdout","text":"Found 8791 images belonging to 31 classes.\nFound 2751 images belonging to 31 classes.\nFound 1760 images belonging to 31 classes.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# INCEPTION MODEL DECLARATION","metadata":{}},{"cell_type":"code","source":"![image.png](attachment:ebb480b6-5247-40b8-bc1c-b1f9cf13825b.png)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:21:46.209278Z","iopub.execute_input":"2025-09-22T07:21:46.209578Z","iopub.status.idle":"2025-09-22T07:21:46.339551Z","shell.execute_reply.started":"2025-09-22T07:21:46.209554Z","shell.execute_reply":"2025-09-22T07:21:46.338898Z"}},"outputs":[{"name":"stdout","text":"/bin/bash: -c: line 1: syntax error near unexpected token `attachment:ebb480b6-5247-40b8-bc1c-b1f9cf13825b.png'\n/bin/bash: -c: line 1: `[image.png](attachment:ebb480b6-5247-40b8-bc1c-b1f9cf13825b.png)'\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#Load Model\ninception = tf.keras.applications.InceptionV3(weights='imagenet',include_top=False,input_shape=(224,224,3))\n#inception.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:21:46.340652Z","iopub.execute_input":"2025-09-22T07:21:46.340945Z","iopub.status.idle":"2025-09-22T07:21:50.474205Z","shell.execute_reply.started":"2025-09-22T07:21:46.340914Z","shell.execute_reply":"2025-09-22T07:21:50.473400Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1758525707.079322      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"inception.trainable = True\nfor layer in inception.layers[:197]:\n    layer.trainable = False ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:21:50.475434Z","iopub.execute_input":"2025-09-22T07:21:50.475749Z","iopub.status.idle":"2025-09-22T07:21:50.481631Z","shell.execute_reply.started":"2025-09-22T07:21:50.475729Z","shell.execute_reply":"2025-09-22T07:21:50.480912Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"for idx, layer in enumerate(inception.layers):\n    print(f' {idx}:  {layer.name}: trainable = {layer.trainable}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:21:50.482317Z","iopub.execute_input":"2025-09-22T07:21:50.482565Z","iopub.status.idle":"2025-09-22T07:21:50.535146Z","shell.execute_reply.started":"2025-09-22T07:21:50.482544Z","shell.execute_reply":"2025-09-22T07:21:50.534576Z"}},"outputs":[{"name":"stdout","text":" 0:  input_layer: trainable = False\n 1:  conv2d: trainable = False\n 2:  batch_normalization: trainable = False\n 3:  activation: trainable = False\n 4:  conv2d_1: trainable = False\n 5:  batch_normalization_1: trainable = False\n 6:  activation_1: trainable = False\n 7:  conv2d_2: trainable = False\n 8:  batch_normalization_2: trainable = False\n 9:  activation_2: trainable = False\n 10:  max_pooling2d: trainable = False\n 11:  conv2d_3: trainable = False\n 12:  batch_normalization_3: trainable = False\n 13:  activation_3: trainable = False\n 14:  conv2d_4: trainable = False\n 15:  batch_normalization_4: trainable = False\n 16:  activation_4: trainable = False\n 17:  max_pooling2d_1: trainable = False\n 18:  conv2d_8: trainable = False\n 19:  batch_normalization_8: trainable = False\n 20:  activation_8: trainable = False\n 21:  conv2d_6: trainable = False\n 22:  conv2d_9: trainable = False\n 23:  batch_normalization_6: trainable = False\n 24:  batch_normalization_9: trainable = False\n 25:  activation_6: trainable = False\n 26:  activation_9: trainable = False\n 27:  average_pooling2d: trainable = False\n 28:  conv2d_5: trainable = False\n 29:  conv2d_7: trainable = False\n 30:  conv2d_10: trainable = False\n 31:  conv2d_11: trainable = False\n 32:  batch_normalization_5: trainable = False\n 33:  batch_normalization_7: trainable = False\n 34:  batch_normalization_10: trainable = False\n 35:  batch_normalization_11: trainable = False\n 36:  activation_5: trainable = False\n 37:  activation_7: trainable = False\n 38:  activation_10: trainable = False\n 39:  activation_11: trainable = False\n 40:  mixed0: trainable = False\n 41:  conv2d_15: trainable = False\n 42:  batch_normalization_15: trainable = False\n 43:  activation_15: trainable = False\n 44:  conv2d_13: trainable = False\n 45:  conv2d_16: trainable = False\n 46:  batch_normalization_13: trainable = False\n 47:  batch_normalization_16: trainable = False\n 48:  activation_13: trainable = False\n 49:  activation_16: trainable = False\n 50:  average_pooling2d_1: trainable = False\n 51:  conv2d_12: trainable = False\n 52:  conv2d_14: trainable = False\n 53:  conv2d_17: trainable = False\n 54:  conv2d_18: trainable = False\n 55:  batch_normalization_12: trainable = False\n 56:  batch_normalization_14: trainable = False\n 57:  batch_normalization_17: trainable = False\n 58:  batch_normalization_18: trainable = False\n 59:  activation_12: trainable = False\n 60:  activation_14: trainable = False\n 61:  activation_17: trainable = False\n 62:  activation_18: trainable = False\n 63:  mixed1: trainable = False\n 64:  conv2d_22: trainable = False\n 65:  batch_normalization_22: trainable = False\n 66:  activation_22: trainable = False\n 67:  conv2d_20: trainable = False\n 68:  conv2d_23: trainable = False\n 69:  batch_normalization_20: trainable = False\n 70:  batch_normalization_23: trainable = False\n 71:  activation_20: trainable = False\n 72:  activation_23: trainable = False\n 73:  average_pooling2d_2: trainable = False\n 74:  conv2d_19: trainable = False\n 75:  conv2d_21: trainable = False\n 76:  conv2d_24: trainable = False\n 77:  conv2d_25: trainable = False\n 78:  batch_normalization_19: trainable = False\n 79:  batch_normalization_21: trainable = False\n 80:  batch_normalization_24: trainable = False\n 81:  batch_normalization_25: trainable = False\n 82:  activation_19: trainable = False\n 83:  activation_21: trainable = False\n 84:  activation_24: trainable = False\n 85:  activation_25: trainable = False\n 86:  mixed2: trainable = False\n 87:  conv2d_27: trainable = False\n 88:  batch_normalization_27: trainable = False\n 89:  activation_27: trainable = False\n 90:  conv2d_28: trainable = False\n 91:  batch_normalization_28: trainable = False\n 92:  activation_28: trainable = False\n 93:  conv2d_26: trainable = False\n 94:  conv2d_29: trainable = False\n 95:  batch_normalization_26: trainable = False\n 96:  batch_normalization_29: trainable = False\n 97:  activation_26: trainable = False\n 98:  activation_29: trainable = False\n 99:  max_pooling2d_2: trainable = False\n 100:  mixed3: trainable = False\n 101:  conv2d_34: trainable = False\n 102:  batch_normalization_34: trainable = False\n 103:  activation_34: trainable = False\n 104:  conv2d_35: trainable = False\n 105:  batch_normalization_35: trainable = False\n 106:  activation_35: trainable = False\n 107:  conv2d_31: trainable = False\n 108:  conv2d_36: trainable = False\n 109:  batch_normalization_31: trainable = False\n 110:  batch_normalization_36: trainable = False\n 111:  activation_31: trainable = False\n 112:  activation_36: trainable = False\n 113:  conv2d_32: trainable = False\n 114:  conv2d_37: trainable = False\n 115:  batch_normalization_32: trainable = False\n 116:  batch_normalization_37: trainable = False\n 117:  activation_32: trainable = False\n 118:  activation_37: trainable = False\n 119:  average_pooling2d_3: trainable = False\n 120:  conv2d_30: trainable = False\n 121:  conv2d_33: trainable = False\n 122:  conv2d_38: trainable = False\n 123:  conv2d_39: trainable = False\n 124:  batch_normalization_30: trainable = False\n 125:  batch_normalization_33: trainable = False\n 126:  batch_normalization_38: trainable = False\n 127:  batch_normalization_39: trainable = False\n 128:  activation_30: trainable = False\n 129:  activation_33: trainable = False\n 130:  activation_38: trainable = False\n 131:  activation_39: trainable = False\n 132:  mixed4: trainable = False\n 133:  conv2d_44: trainable = False\n 134:  batch_normalization_44: trainable = False\n 135:  activation_44: trainable = False\n 136:  conv2d_45: trainable = False\n 137:  batch_normalization_45: trainable = False\n 138:  activation_45: trainable = False\n 139:  conv2d_41: trainable = False\n 140:  conv2d_46: trainable = False\n 141:  batch_normalization_41: trainable = False\n 142:  batch_normalization_46: trainable = False\n 143:  activation_41: trainable = False\n 144:  activation_46: trainable = False\n 145:  conv2d_42: trainable = False\n 146:  conv2d_47: trainable = False\n 147:  batch_normalization_42: trainable = False\n 148:  batch_normalization_47: trainable = False\n 149:  activation_42: trainable = False\n 150:  activation_47: trainable = False\n 151:  average_pooling2d_4: trainable = False\n 152:  conv2d_40: trainable = False\n 153:  conv2d_43: trainable = False\n 154:  conv2d_48: trainable = False\n 155:  conv2d_49: trainable = False\n 156:  batch_normalization_40: trainable = False\n 157:  batch_normalization_43: trainable = False\n 158:  batch_normalization_48: trainable = False\n 159:  batch_normalization_49: trainable = False\n 160:  activation_40: trainable = False\n 161:  activation_43: trainable = False\n 162:  activation_48: trainable = False\n 163:  activation_49: trainable = False\n 164:  mixed5: trainable = False\n 165:  conv2d_54: trainable = False\n 166:  batch_normalization_54: trainable = False\n 167:  activation_54: trainable = False\n 168:  conv2d_55: trainable = False\n 169:  batch_normalization_55: trainable = False\n 170:  activation_55: trainable = False\n 171:  conv2d_51: trainable = False\n 172:  conv2d_56: trainable = False\n 173:  batch_normalization_51: trainable = False\n 174:  batch_normalization_56: trainable = False\n 175:  activation_51: trainable = False\n 176:  activation_56: trainable = False\n 177:  conv2d_52: trainable = False\n 178:  conv2d_57: trainable = False\n 179:  batch_normalization_52: trainable = False\n 180:  batch_normalization_57: trainable = False\n 181:  activation_52: trainable = False\n 182:  activation_57: trainable = False\n 183:  average_pooling2d_5: trainable = False\n 184:  conv2d_50: trainable = False\n 185:  conv2d_53: trainable = False\n 186:  conv2d_58: trainable = False\n 187:  conv2d_59: trainable = False\n 188:  batch_normalization_50: trainable = False\n 189:  batch_normalization_53: trainable = False\n 190:  batch_normalization_58: trainable = False\n 191:  batch_normalization_59: trainable = False\n 192:  activation_50: trainable = False\n 193:  activation_53: trainable = False\n 194:  activation_58: trainable = False\n 195:  activation_59: trainable = False\n 196:  mixed6: trainable = False\n 197:  conv2d_64: trainable = True\n 198:  batch_normalization_64: trainable = True\n 199:  activation_64: trainable = True\n 200:  conv2d_65: trainable = True\n 201:  batch_normalization_65: trainable = True\n 202:  activation_65: trainable = True\n 203:  conv2d_61: trainable = True\n 204:  conv2d_66: trainable = True\n 205:  batch_normalization_61: trainable = True\n 206:  batch_normalization_66: trainable = True\n 207:  activation_61: trainable = True\n 208:  activation_66: trainable = True\n 209:  conv2d_62: trainable = True\n 210:  conv2d_67: trainable = True\n 211:  batch_normalization_62: trainable = True\n 212:  batch_normalization_67: trainable = True\n 213:  activation_62: trainable = True\n 214:  activation_67: trainable = True\n 215:  average_pooling2d_6: trainable = True\n 216:  conv2d_60: trainable = True\n 217:  conv2d_63: trainable = True\n 218:  conv2d_68: trainable = True\n 219:  conv2d_69: trainable = True\n 220:  batch_normalization_60: trainable = True\n 221:  batch_normalization_63: trainable = True\n 222:  batch_normalization_68: trainable = True\n 223:  batch_normalization_69: trainable = True\n 224:  activation_60: trainable = True\n 225:  activation_63: trainable = True\n 226:  activation_68: trainable = True\n 227:  activation_69: trainable = True\n 228:  mixed7: trainable = True\n 229:  conv2d_72: trainable = True\n 230:  batch_normalization_72: trainable = True\n 231:  activation_72: trainable = True\n 232:  conv2d_73: trainable = True\n 233:  batch_normalization_73: trainable = True\n 234:  activation_73: trainable = True\n 235:  conv2d_70: trainable = True\n 236:  conv2d_74: trainable = True\n 237:  batch_normalization_70: trainable = True\n 238:  batch_normalization_74: trainable = True\n 239:  activation_70: trainable = True\n 240:  activation_74: trainable = True\n 241:  conv2d_71: trainable = True\n 242:  conv2d_75: trainable = True\n 243:  batch_normalization_71: trainable = True\n 244:  batch_normalization_75: trainable = True\n 245:  activation_71: trainable = True\n 246:  activation_75: trainable = True\n 247:  max_pooling2d_3: trainable = True\n 248:  mixed8: trainable = True\n 249:  conv2d_80: trainable = True\n 250:  batch_normalization_80: trainable = True\n 251:  activation_80: trainable = True\n 252:  conv2d_77: trainable = True\n 253:  conv2d_81: trainable = True\n 254:  batch_normalization_77: trainable = True\n 255:  batch_normalization_81: trainable = True\n 256:  activation_77: trainable = True\n 257:  activation_81: trainable = True\n 258:  conv2d_78: trainable = True\n 259:  conv2d_79: trainable = True\n 260:  conv2d_82: trainable = True\n 261:  conv2d_83: trainable = True\n 262:  average_pooling2d_7: trainable = True\n 263:  conv2d_76: trainable = True\n 264:  batch_normalization_78: trainable = True\n 265:  batch_normalization_79: trainable = True\n 266:  batch_normalization_82: trainable = True\n 267:  batch_normalization_83: trainable = True\n 268:  conv2d_84: trainable = True\n 269:  batch_normalization_76: trainable = True\n 270:  activation_78: trainable = True\n 271:  activation_79: trainable = True\n 272:  activation_82: trainable = True\n 273:  activation_83: trainable = True\n 274:  batch_normalization_84: trainable = True\n 275:  activation_76: trainable = True\n 276:  mixed9_0: trainable = True\n 277:  concatenate: trainable = True\n 278:  activation_84: trainable = True\n 279:  mixed9: trainable = True\n 280:  conv2d_89: trainable = True\n 281:  batch_normalization_89: trainable = True\n 282:  activation_89: trainable = True\n 283:  conv2d_86: trainable = True\n 284:  conv2d_90: trainable = True\n 285:  batch_normalization_86: trainable = True\n 286:  batch_normalization_90: trainable = True\n 287:  activation_86: trainable = True\n 288:  activation_90: trainable = True\n 289:  conv2d_87: trainable = True\n 290:  conv2d_88: trainable = True\n 291:  conv2d_91: trainable = True\n 292:  conv2d_92: trainable = True\n 293:  average_pooling2d_8: trainable = True\n 294:  conv2d_85: trainable = True\n 295:  batch_normalization_87: trainable = True\n 296:  batch_normalization_88: trainable = True\n 297:  batch_normalization_91: trainable = True\n 298:  batch_normalization_92: trainable = True\n 299:  conv2d_93: trainable = True\n 300:  batch_normalization_85: trainable = True\n 301:  activation_87: trainable = True\n 302:  activation_88: trainable = True\n 303:  activation_91: trainable = True\n 304:  activation_92: trainable = True\n 305:  batch_normalization_93: trainable = True\n 306:  activation_85: trainable = True\n 307:  mixed9_1: trainable = True\n 308:  concatenate_1: trainable = True\n 309:  activation_93: trainable = True\n 310:  mixed10: trainable = True\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#get the last layer    \nlast_layer = inception.get_layer('mixed7')\n\nlayer_output = last_layer.output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:21:50.535915Z","iopub.execute_input":"2025-09-22T07:21:50.536151Z","iopub.status.idle":"2025-09-22T07:21:50.548362Z","shell.execute_reply.started":"2025-09-22T07:21:50.536128Z","shell.execute_reply":"2025-09-22T07:21:50.547814Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"n_categories = len(os.listdir('../input/fish-dataset/FishImgDataset/train'))# number of categories\nprint(n_categories)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:21:50.549153Z","iopub.execute_input":"2025-09-22T07:21:50.549662Z","iopub.status.idle":"2025-09-22T07:21:50.563160Z","shell.execute_reply.started":"2025-09-22T07:21:50.549639Z","shell.execute_reply":"2025-09-22T07:21:50.562449Z"}},"outputs":[{"name":"stdout","text":"31\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# MODEL MODIFICATION","metadata":{}},{"cell_type":"code","source":"# x  = BatchNormalization()(layer_output)\nxs = Flatten()(layer_output)\nxs = Dense(1024,activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001))(xs)\nxs = Dropout(0.4)(xs)\nxs = Dense(n_categories, activation='softmax')(xs)\n\nmodel = Model(inputs=inception.inputs, outputs=xs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:21:50.564105Z","iopub.execute_input":"2025-09-22T07:21:50.564792Z","iopub.status.idle":"2025-09-22T07:21:50.654277Z","shell.execute_reply.started":"2025-09-22T07:21:50.564774Z","shell.execute_reply":"2025-09-22T07:21:50.653701Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# COMPILING MODEL","metadata":{}},{"cell_type":"code","source":"# Set the training parameters\nmodel.compile(optimizer = RMSprop(learning_rate=0.0001), \n              loss = 'categorical_crossentropy', \n              metrics = ['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:21:50.654940Z","iopub.execute_input":"2025-09-22T07:21:50.655117Z","iopub.status.idle":"2025-09-22T07:21:50.667858Z","shell.execute_reply.started":"2025-09-22T07:21:50.655103Z","shell.execute_reply":"2025-09-22T07:21:50.667242Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# CALLBACKS","metadata":{}},{"cell_type":"code","source":"def scheduler(epoch, lr):\n    if epoch < 10:\n        return lr\n    else:\n        return lr * tf.math.exp(-0.1)\n    \ncallback = tf.keras.callbacks.LearningRateScheduler(scheduler)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:21:50.670982Z","iopub.execute_input":"2025-09-22T07:21:50.671193Z","iopub.status.idle":"2025-09-22T07:21:50.675303Z","shell.execute_reply.started":"2025-09-22T07:21:50.671178Z","shell.execute_reply":"2025-09-22T07:21:50.674811Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# MODEL FITTING","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n            train_generator,\n            validation_data = validation_generator,\n            epochs = 10, #10\n            callbacks=[callback])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T07:21:50.675991Z","iopub.execute_input":"2025-09-22T07:21:50.676193Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\nExpected: ['keras_tensor']\nReceived: inputs=Tensor(shape=(None, 224, 224, 3))\n  warnings.warn(msg)\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1758525723.477581     114 service.cc:148] XLA service 0x798668001f60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1758525723.478440     114 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1758525725.114982     114 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  2/275\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 61ms/step - accuracy: 0.0703 - loss: 6.0951   ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1758525732.337454     114 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - accuracy: 0.5077 - loss: 3.8537","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# LOSS AND VALIDATION LOSS","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.legend()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ACCURACY AND VALIDATION ACCURACY","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='acc')\nplt.plot(history.history['val_accuracy'], label='val_acc')\nplt.legend()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SAVING OF MODEL CLASSIFIER","metadata":{}},{"cell_type":"code","source":"model_name = 'FishModelClassifier_V6.h5'\nmodel.save(model_name, save_format='h5')\nmodel.save_weights('model_weights_V6.weights.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = model.evaluate(test_generator, verbose=0)\n\n\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PREDICTION OF NEW DATA /W IMG","metadata":{}},{"cell_type":"code","source":"class_names = ['Bangus', 'Big Head Carp', 'Black Spotted Barb', 'Catfish', 'Climbing Perch', 'Fourfinger Threadfin',\n               'Freshwater Eel', 'Glass Perchlet', 'Goby', 'Gold Fish', 'Gourami', 'Grass Carp', 'Green Spotted Puffer',\n               'Indian Carp', 'Indo-Pacific Tarpon', 'Jaguar Gapote', 'Janitor Fish', 'Knifefish', 'Long-Snouted Pipefish',\n               'Mosquito Fish', 'Mudfish', 'Mullet', 'Pangasius', 'Perch', 'Scat Fish', 'Silver Barb', 'Silver Carp',\n               'Silver Perch', 'Snakehead', 'Tenpounder', 'Tilapia']\n\n# Use next() function instead of .next() method\nimages, labels = next(test_generator)\npreds = model.predict(images)\n\nfig, axes = plt.subplots(nrows=2, ncols=4, figsize=(25,25))\ndic = {i: ax for i, ax in enumerate(axes.flat)}\n\nfor i in range(0, 8):\n    label = np.argmax(labels[i])\n    pred = np.argmax(preds[i])\n    image = images[i]\n    dic[i].set_title(\"real label: \" + str(class_names[label]) + \" v.s \" + \"predictedd lable: \" + str(class_names[pred]))\n    dic[i].imshow(image)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PREDICTION OF NEW DATA","metadata":{}},{"cell_type":"code","source":"from keras.models import load_model\nfrom keras.preprocessing.image import load_img, img_to_array\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\n\n# Use the actual model file that exists in your directory\nmodel_path = './FishModelClassifier_V6.h5'\n\n# Check if model file exists\nif os.path.exists(model_path):\n    print(f\"Model file found at: {model_path}\")\nelse:\n    print(f\"Error: Model file not found at {model_path}\")\n    print(f\"Current directory contents: {os.listdir('.')}\")\n    # Stop execution if model not found\n    raise FileNotFoundError(f\"Model file not found at {model_path}\")\n\n# Load the model\ntry:\n    model = load_model(model_path, compile=False)\n    print(f\"Model loaded successfully from: {model_path}\")\nexcept Exception as e:\n    print(f\"Error loading model: {e}\")\n    raise\n\nclass_names = ['Bangus', 'Big Head Carp', 'Black Spotted Barb', 'Catfish', 'Climbing Perch', 'Fourfinger Threadfin',\n               'Freshwater Eel', 'Glass Perchlet', 'Goby', 'Gold Fish', 'Gourami', 'Grass Carp', 'Green Spotted Puffer',\n               'Indian Carp', 'Indo-Pacific Tarpon', 'Jaguar Gapote', 'Janitor Fish', 'Knifefish', 'Long-Snouted Pipefish',\n               'Mosquito Fish', 'Mudfish', 'Mullet', 'Pangasius', 'Perch', 'Scat Fish', 'Silver Barb', 'Silver Carp',\n               'Silver Perch', 'Snakehead', 'Tenpounder', 'Tilapia']\n\ndef predict(path):\n    # Check if image file exists\n    if not os.path.exists(path):\n        print(f\"Image file not found at: {path}\")\n        return None\n    \n    try:\n        img = load_img(path, target_size=(224, 224, 3))  # Convert image size and declare the kernel\n        img = img_to_array(img)  # Convert the image to an image array\n        img = img/255  # Normalize RGB values\n        img = np.expand_dims(img, [0])\n        answer = model.predict(img)\n        x = list(np.argsort(answer[0])[::-1][:5])\n        \n        print(\"Top 5 predictions:\")\n        for i in x:\n            print(\"{className}: {predVal:.2f}%\".format(className=class_names[i], predVal=float(answer[0][i])*100))\n        \n        y_class = answer.argmax(axis=-1)\n        y = \" \".join(str(x) for x in y_class)\n        y = int(y)\n        res = class_names[y]\n        \n        return res\n    except Exception as e:\n        print(f\"Error during prediction: {e}\")\n        return None\n\n# Test with a sample image path - modify this to point to your actual test image\ntest_image_paths = [\n    '../input/fish-dataset/FishImgDataset/test/Mudfish/Mudfish 013.jpg',\n    './test_images/sample_fish.jpg',  # Alternative path\n    './sample_fish.jpg'  # Another alternative\n]\n\n# Try to find a valid test image\ntest_image_found = False\nfor img_path in test_image_paths:\n    if os.path.exists(img_path):\n        print(f\"Found test image at: {img_path}\")\n        result = predict(img_path)\n        \n        if result:\n            print(f\"Predicted species: {result}\")\n            \n            # Display the image\n            try:\n                img = load_img(img_path, target_size=(224, 224, 3))\n                plt.figure(figsize=(8, 6))\n                plt.imshow(img, aspect=\"auto\")\n                plt.axis('off')\n                plt.title(f\"Predicted Fish Species: {result}\")\n                plt.show()\n            except Exception as e:\n                print(f\"Error displaying image: {e}\")\n        \n        test_image_found = True\n        break\n\nif not test_image_found:\n    print(\"No test image found. Please provide a valid image path.\")\n    print(\"Available files in current directory:\")\n    for file in os.listdir('.'):\n        if file.endswith(('.jpg', '.jpeg', '.png')):\n            print(f\"  - {file}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# VISUALISING FEATURE MAP","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport random\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\n\n# Get list of layers from model\nlayer_outputs = [layer.output for layer in model.layers[1:]]\n# Create a visualization model\nvisualize_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load image for prediction\nimg=load_img('../input/fish-dataset/FishImgDataset/test/Mudfish/Mudfish 013.jpg',target_size=(224,224))\n# Convert image to array\nx = img_to_array(img)\n# Print shape of array\nx.shape\n\n# Reshape image for passing it to prediction\nx=x.reshape((1,224,224,3))\nprint(x.shape)\n# Rescale the image\nx = x /255 \n\n# Get all layers feature maps for image\nfeature_maps=visualize_model.predict(x)\nprint(len(feature_maps))\n# Show names of layers available in model\nlayer_names = [layer.name for layer in model.layers]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotting the graph\nfor layer_names, feature_maps in zip(layer_names,feature_maps):\n  print(feature_maps.shape)\n  if len(feature_maps.shape) == 4 :\n    channels = feature_maps.shape[-1]\n    size = feature_maps.shape[1]\n    display_grid = np.zeros((size, size * channels))\n    for i in range(channels):\n      x = feature_maps[0, :, :, i]\n      x -= x.mean()\n      x /= x.std()\n      x *= 64\n      x += 128\n      x = np.clip(x, 0, 255).astype('uint8')\n      # We'll tile each filter into this big horizontal grid\n      display_grid[:, i * size : (i + 1) * size] = x\n\n    scale = 20. / channels\n    plt.figure(figsize=(scale * channels, scale))\n    plt.title(layer_names)\n    plt.grid(False)\n    plt.imshow(display_grid, aspect='auto', cmap='viridis')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CONFUSION MATRIX","metadata":{}},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap='rainbow'):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize=(20,20))\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        cm = np.around(cm, decimals=2)\n        cm[np.isnan(cm)] = 0.0\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"white\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.savefig('confusion_matrix.png')\n    \n# Print the Target names\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\nimport numpy as np\n\n# First, check if generators exist, if not create them\ntry:\n    # Check if train_generator exists\n    if 'train_generator' not in locals() or 'train_generator' not in globals():\n        print(\"train_generator not found. Creating data generators...\")\n        \n        # Recreate the data generators (adjust paths according to your setup)\n        from tensorflow.keras.preprocessing.image import ImageDataGenerator\n        \n        # Data augmentation for training\n        train_datagen = ImageDataGenerator(\n            rescale=1./255,\n            shear_range=0.2,\n            zoom_range=0.2,\n            horizontal_flip=True\n        )\n        \n        # Only rescaling for validation/test\n        test_datagen = ImageDataGenerator(rescale=1./255)\n        \n        # Create generators (adjust paths to your dataset)\n        train_generator = train_datagen.flow_from_directory(\n            '../input/fish-dataset/FishImgDataset/train',  # Adjust path\n            target_size=(224, 224),\n            batch_size=32,\n            class_mode='categorical'\n        )\n        \n        test_generator = test_datagen.flow_from_directory(\n            '../input/fish-dataset/FishImgDataset/test',  # Adjust path\n            target_size=(224, 224),\n            batch_size=32,\n            class_mode='categorical',\n            shuffle=False\n        )\n        \n        print(\"Data generators created successfully!\")\n    \n    # Now extract target names\n    target_names = []\n    for key in train_generator.class_indices:\n        target_names.append(key)\n    \n    print(f\"Target names: {target_names}\")\n    print(f\"Number of classes: {len(target_names)}\")\n    \n    # Confusion Matrix\n    print(\"Generating predictions...\")\n    \n    # Use model.predict() instead of model.predict_generator()\n    Y_pred = model.predict(test_generator, verbose=1)\n    y_pred = np.argmax(Y_pred, axis=1)\n    \n    print('Confusion Matrix')\n    cm = confusion_matrix(test_generator.classes, y_pred)\n    plot_confusion_matrix(cm, target_names, title='Confusion Matrix')\n    \n    # Print Classification Report\n    print('Classification Report')\n    print(classification_report(test_generator.classes, y_pred, target_names=target_names))\n    \n    # Additional metrics\n    print(f\"Total test samples: {len(y_pred)}\")\n    print(f\"Prediction shape: {Y_pred.shape}\")\n    \nexcept Exception as e:\n    print(f\"Error: {e}\")\n    print(\"Please ensure your data generators are properly created and the model is loaded.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# FINE TUNING MODEL","metadata":{}},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap='rainbow'):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize=(20,20))\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        cm = np.around(cm, decimals=2)\n        cm[np.isnan(cm)] = 0.0\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"white\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.savefig('confusion_matrix.png')\n    \n# Print the Target names\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\nimport numpy as np\n\n# First, check if generators exist, if not create them\ntry:\n    # Check if train_generator exists\n    if 'train_generator' not in locals() or 'train_generator' not in globals():\n        print(\"train_generator not found. Creating data generators...\")\n        \n        # Recreate the data generators (adjust paths according to your setup)\n        from tensorflow.keras.preprocessing.image import ImageDataGenerator\n        \n        # Data augmentation for training\n        train_datagen = ImageDataGenerator(\n            rescale=1./255,\n            shear_range=0.2,\n            zoom_range=0.2,\n            horizontal_flip=True\n        )\n        \n        # Only rescaling for validation/test\n        test_datagen = ImageDataGenerator(rescale=1./255)\n        \n        # Create generators (adjust paths to your dataset)\n        train_generator = train_datagen.flow_from_directory(\n            '../input/fish-dataset/FishImgDataset/train',  # Adjust path\n            target_size=(224, 224),\n            batch_size=32,\n            class_mode='categorical'\n        )\n        \n        test_generator = test_datagen.flow_from_directory(\n            '../input/fish-dataset/FishImgDataset/test',  # Adjust path\n            target_size=(224, 224),\n            batch_size=32,\n            class_mode='categorical',\n            shuffle=False\n        )\n        \n        print(\"Data generators created successfully!\")\n    \n    # Now extract target names\n    target_names = []\n    for key in train_generator.class_indices:\n        target_names.append(key)\n    \n    print(f\"Target names: {target_names}\")\n    print(f\"Number of classes: {len(target_names)}\")\n    \n    # Confusion Matrix\n    print(\"Generating predictions...\")\n    \n    # Use model.predict() instead of model.predict_generator()\n    Y_pred = model.predict(test_generator, verbose=1)\n    y_pred = np.argmax(Y_pred, axis=1)\n    \n    print('Confusion Matrix')\n    cm = confusion_matrix(test_generator.classes, y_pred)\n    plot_confusion_matrix(cm, target_names, title='Confusion Matrix')\n    \n    # Print Classification Report\n    print('Classification Report')\n    print(classification_report(test_generator.classes, y_pred, target_names=target_names))\n    \n    # Additional metrics\n    print(f\"Total test samples: {len(y_pred)}\")\n    print(f\"Prediction shape: {Y_pred.shape}\")\n    \nexcept Exception as e:\n    print(f\"Error: {e}\")\n    print(\"Please ensure your data generators are properly created and the model is loaded.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=10, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\n\n\ninception.trainable = False\nfor layer in model.layers[:290]:\n   layer.trainable = False\nfor layer in model.layers[290:]:\n   layer.trainable = True","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile the model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n# Set up model checkpoint\nfilepath = \"./FishModelClassifier.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint, learning_rate_reduction]\n\n# Training parameters\nsteps_per_epoch = 32\n\n# Use model.fit() instead of fit_generator()\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=steps_per_epoch,\n    validation_data=test_generator,\n    validation_steps=5,\n    callbacks=callbacks_list,\n    epochs=5,\n    verbose=2\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\n# Check if test_generator is properly defined\nif 'test_generator' not in locals():\n    print(\"Error: test_generator not defined. Please ensure you have created your test data generator.\")\nelse:\n    try:\n        # Use model.evaluate() - works with generators in TensorFlow 2.x\n        print(\"Evaluating model on test data...\")\n        \n        # If batch_size is not defined, remove it or set a default\n        if 'batch_size' not in locals():\n            batch_size = 32  # Set default batch size\n        \n        # Evaluate the model\n        test_score = model.evaluate(test_generator, verbose=1)\n        \n        # Display results\n        print(f\"[INFO] Test Loss: {test_score[0]:.4f}\")\n        print(f\"[INFO] Test Accuracy: {test_score[1]*100:.2f}%\")\n        \n    except Exception as e:\n        print(f\"Error during model evaluation: {e}\")\n        \n        # Fallback for very old TensorFlow versions (unlikely but just in case)\n        if hasattr(model, 'evaluate_generator'):\n            print(\"Falling back to evaluate_generator for older TensorFlow version...\")\n            test_score = model.evaluate_generator(test_generator, batch_size)\n            print(f\"[INFO] Test Accuracy: {test_score[1]*100:.2f}%\")\n            print(f\"[INFO] Test Loss: {test_score[0]:.4f}\")\n        else:\n            print(\"Both evaluate() and evaluate_generator() methods failed.\")\n            raise e","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Plot the Graph\n\n# Loss Curves\nplt.figure(figsize=[8,6])\nplt.plot(history.history['loss'],'r',linewidth=3.0)\nplt.plot(history.history['val_loss'],'b',linewidth=3.0)\nplt.legend(['Training loss', 'Validation Loss'],fontsize=18)\nplt.xlabel('Epochs ',fontsize=16)\nplt.ylabel('Loss',fontsize=16)\nplt.title('Loss Curves',fontsize=16)\n  \n# Accuracy Curves\nplt.figure(figsize=[8,6])\nplt.plot(history.history['accuracy'],'r',linewidth=3.0)\nplt.plot(history.history['val_accuracy'],'b',linewidth=3.0)\nplt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\nplt.xlabel('Epochs ',fontsize=16)\nplt.ylabel('Accuracy',fontsize=16)\nplt.title('Accuracy Curves',fontsize=16)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# INTERFACE","metadata":{}},{"cell_type":"code","source":"import ipywidgets as widgets\nfrom IPython.display import display, clear_output\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport io\nimport numpy as np\nfrom keras.preprocessing.image import img_to_array\nimport os\n\n# Define class names for fish species\nclass_names = ['Bangus', 'Big Head Carp', 'Black Spotted Barb', 'Catfish', 'Climbing Perch', 'Fourfinger Threadfin',\n               'Freshwater Eel', 'Glass Perchlet', 'Goby', 'Gold Fish', 'Gourami', 'Grass Carp', 'Green Spotted Puffer',\n               'Indian Carp', 'Indo-Pacific Tarpon', 'Jaguar Gapote', 'Janitor Fish', 'Knifefish', 'Long-Snouted Pipefish',\n               'Mosquito Fish', 'Mudfish', 'Mullet', 'Pangasius', 'Perch', 'Scat Fish', 'Silver Barb', 'Silver Carp',\n               'Silver Perch', 'Snakehead', 'Tenpounder', 'Tilapia']\n\n# Create output widgets for results\noutput = widgets.Output()\nresult_output = widgets.Output()\n\ndef preprocess_image(image):\n    \"\"\"Preprocess the image for model prediction\"\"\"\n    try:\n        # Resize image to match model input (224x224)\n        image = image.resize((224, 224))\n        \n        # Convert to array\n        img_array = img_to_array(image)\n        \n        # Normalize pixel values (0-1)\n        img_array = img_array / 255.0\n        \n        # Add batch dimension\n        img_array = np.expand_dims(img_array, axis=0)\n        \n        return img_array\n    except Exception as e:\n        print(f\"Error preprocessing image: {e}\")\n        return None\n\ndef predict_fish_species(image_array):\n    \"\"\"Make prediction using the trained model\"\"\"\n    try:\n        # Make prediction\n        predictions = model.predict(image_array, verbose=0)\n        \n        # Get top 3 predictions\n        top_indices = np.argsort(predictions[0])[::-1][:3]\n        \n        results = []\n        for i, idx in enumerate(top_indices):\n            confidence = predictions[0][idx] * 100\n            results.append((class_names[idx], confidence))\n        \n        return results\n    except Exception as e:\n        print(f\"Error during prediction: {e}\")\n        return None\n\ndef on_upload_change(change):\n    \"\"\"Handle file upload - Fixed for newer ipywidgets versions\"\"\"\n    with output:\n        clear_output(wait=True)\n        \n        # Check if files were uploaded\n        if change['new']:\n            try:\n                # In newer versions of ipywidgets, change['new'] is a tuple of file dictionaries\n                if isinstance(change['new'], tuple) and len(change['new']) > 0:\n                    # Get the first uploaded file from the tuple\n                    uploaded_file = change['new'][0]\n                elif isinstance(change['new'], dict):\n                    # For older versions where it might still be a dict\n                    uploaded_file = list(change['new'].values())[0]\n                else:\n                    print(\"No files uploaded or unexpected file format\")\n                    return\n                \n                # Debug: Check the structure of uploaded_file\n                print(f\"File info: {uploaded_file.get('name', 'Unknown')} ({uploaded_file.get('size', 0)} bytes)\")\n                \n                # Load image from uploaded bytes\n                image = Image.open(io.BytesIO(uploaded_file['content']))\n                \n                # Convert to RGB if needed\n                if image.mode != 'RGB':\n                    image = image.convert('RGB')\n                \n                # Display the uploaded image\n                plt.figure(figsize=(8, 6))\n                plt.imshow(image)\n                plt.axis('off')\n                plt.title(f'Uploaded Image: {uploaded_file.get(\"name\", \"Unknown\")}')\n                plt.show()\n                \n                # Preprocess image\n                processed_image = preprocess_image(image)\n                \n                if processed_image is not None:\n                    # Make prediction\n                    with result_output:\n                        clear_output(wait=True)\n                        print(\"🐟 Analyzing Image\")\n                        \n                        predictions = predict_fish_species(processed_image)\n                        \n                        if predictions:\n                            print(\"\\n\" + \"=\"*50)\n                            print(\" FISH SPECIES PREDICTION RESULTS\")\n                            print(\"=\"*50)\n                            \n                            for i, (species, confidence) in enumerate(predictions, 1):\n                                if i == 1:\n                                    print(f\"TOP PREDICTION: {species}\")\n                                    print(f\"   Confidence: {confidence:.2f}%\")\n                                else:\n                                    print(f\"#{i}  {species}: {confidence:.2f}%\")\n                            \n                            print(\"\\n\" + \"=\"*50)\n                            \n                            # Show confidence level interpretation\n                            top_confidence = predictions[0][1]\n                            if top_confidence > 90:\n                                print(\" Very High Confidence - Excellent prediction!\")\n                            elif top_confidence > 70:\n                                print(\" High Confidence - Good prediction!\")\n                            elif top_confidence > 50:\n                                print(\"  Moderate Confidence - Consider additional verification\")\n                            else:\n                                print(\" Low Confidence - Image may be unclear or species not well represented\")\n                \n            except Exception as e:\n                print(f\" Error processing image: {e}\")\n                print(\"Please try uploading a different image file (JPG, PNG, or JPEG)\")\n\ndef predict_from_path():\n    \"\"\"Predict from a file path input\"\"\"\n    file_path = path_input.value.strip()\n    \n    with path_output:\n        clear_output(wait=True)\n        \n        if not file_path:\n            print(\"Please enter a valid file path\")\n            return\n        \n        if not os.path.exists(file_path):\n            print(f\" File not found: {file_path}\")\n            return\n        \n        try:\n            # Load image from path\n            image = Image.open(file_path)\n            \n            # Convert to RGB if needed\n            if image.mode != 'RGB':\n                image = image.convert('RGB')\n            \n            # Display the image\n            plt.figure(figsize=(8, 6))\n            plt.imshow(image)\n            plt.axis('off')\n            plt.title(f'Image: {os.path.basename(file_path)}')\n            plt.show()\n            \n            # Preprocess and predict\n            processed_image = preprocess_image(image)\n            \n            if processed_image is not None:\n                predictions = predict_fish_species(processed_image)\n                \n                if predictions:\n                    print(\"\\n\" + \"=\"*50)\n                    print(\"FISH SPECIES PREDICTION RESULTS\")\n                    print(\"=\"*50)\n                    \n                    for i, (species, confidence) in enumerate(predictions, 1):\n                        if i == 1:\n                            print(f\"🥇 TOP PREDICTION: {species}\")\n                            print(f\"   Confidence: {confidence:.2f}%\")\n                        else:\n                            print(f\"#{i}  {species}: {confidence:.2f}%\")\n        \n        except Exception as e:\n            print(f\" Error processing image: {e}\")\n\n# Create upload widget\nupload_widget = widgets.FileUpload(\n    accept='.jpg,.jpeg,.png',  # Accept image files\n    multiple=False,\n    description='Upload Fish Image',\n    tooltip='Select a fish image for classification'\n)\n\n# Create file path input widget\npath_input = widgets.Text(\n    placeholder='Enter image file path...',\n    description='File Path:',\n    style={'description_width': 'initial'}\n)\n\n# Create button for path prediction\npath_button = widgets.Button(\n    description='Predict from Path',\n    button_style='info',\n    tooltip='Click to predict from file path'\n)\n\n# Create output widget for path predictions\npath_output = widgets.Output()\n\n# Connect widgets to functions\nupload_widget.observe(on_upload_change, names='value')\npath_button.on_click(lambda x: predict_from_path())\n\n# Create the user interface\nprint(\"FISH SPECIES CLASSIFICATION SYSTEM\")\nprint(\"=\"*50)\nprint(\"Choose one of the following methods to classify a fish image:\")\n\n# Method 1: File Upload\nprint(\"\\nMETHOD 1: Upload Image File\")\ndisplay(upload_widget)\ndisplay(output)\ndisplay(result_output)\n\nprint(\"\\n\" + \"-\"*50)\n\n# Method 2: File Path Input\nprint(\"\\nMETHOD 2: Enter Image File Path\")\ndisplay(widgets.HBox([path_input, path_button]))\ndisplay(path_output)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"📋 INSTRUCTIONS:\")\nprint(\"• Upload a clear image of a fish (JPG, PNG, or JPEG format)\")\nprint(\"• Ensure the fish is clearly visible and well-lit\")\nprint(\"• The model can classify 31 different fish species\")\nprint(\"• Higher confidence scores indicate more reliable predictions\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}